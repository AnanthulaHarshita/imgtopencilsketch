{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import PIL\n",
    "from packaging import version\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Generator (U-Net with skip connections)\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=1, ngf=64):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "\n",
    "        def down_block(in_channels, out_channels, apply_batchnorm=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "            if apply_batchnorm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def up_block(in_channels, out_channels, apply_dropout=False):\n",
    "            layers = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                      nn.BatchNorm2d(out_channels),\n",
    "                      nn.ReLU(inplace=True)]\n",
    "            if apply_dropout:\n",
    "                layers.append(nn.Dropout(0.5))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        # Encoder (Downsampling layers)\n",
    "        self.down1 = down_block(input_nc, ngf, apply_batchnorm=False)\n",
    "        self.down2 = down_block(ngf, ngf * 2)\n",
    "        self.down3 = down_block(ngf * 2, ngf * 4)\n",
    "        self.down4 = down_block(ngf * 4, ngf * 8)\n",
    "        self.down5 = down_block(ngf * 8, ngf * 8)\n",
    "        self.down6 = down_block(ngf * 8, ngf * 8)\n",
    "        self.down7 = down_block(ngf * 8, ngf * 8)\n",
    "        self.down8 = down_block(ngf * 8, ngf * 8, apply_batchnorm=False)\n",
    "\n",
    "        # Decoder (Upsampling layers)\n",
    "        self.up1 = up_block(ngf * 8, ngf * 8, apply_dropout=True)\n",
    "        self.up2 = up_block(ngf * 8 * 2, ngf * 8, apply_dropout=True)\n",
    "        self.up3 = up_block(ngf * 8 * 2, ngf * 8, apply_dropout=True)\n",
    "        self.up4 = up_block(ngf * 8 * 2, ngf * 8)\n",
    "        self.up5 = up_block(ngf * 8 * 2, ngf * 4)\n",
    "        self.up6 = up_block(ngf * 4 * 2, ngf * 2)\n",
    "        self.up7 = up_block(ngf * 2 * 2, ngf)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 2, output_nc, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        u1 = self.up1(d8)\n",
    "        u2 = self.up2(torch.cat([u1, d7], 1))\n",
    "        u3 = self.up3(torch.cat([u2, d6], 1))\n",
    "        u4 = self.up4(torch.cat([u3, d5], 1))\n",
    "        u5 = self.up5(torch.cat([u4, d4], 1))\n",
    "        u6 = self.up6(torch.cat([u5, d3], 1))\n",
    "        u7 = self.up7(torch.cat([u6, d2], 1))\n",
    "        return self.final(torch.cat([u7, d1], 1))\n",
    "\n",
    "\n",
    "# PatchGAN Discriminator\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=1, ndf=64):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_block(in_channels, out_channels, stride=2, apply_batchnorm=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1, bias=False)]\n",
    "            if apply_batchnorm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            disc_block(input_nc + output_nc, ndf, apply_batchnorm=False),\n",
    "            disc_block(ndf, ndf * 2),\n",
    "            disc_block(ndf * 2, ndf * 4),\n",
    "            disc_block(ndf * 4, ndf * 8, stride=1),\n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, sketch):\n",
    "        input = torch.cat((img, sketch), 1)  # Concatenate input and output\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "# Define paths\n",
    "CHECKPOINT_PATH = \"pix2pix_checkpoint_pencil.pth\"\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ 1. Check PyTorch & CUDA Versions\n",
    "# ------------------------------\n",
    "print(\"\\nüî• Checking PyTorch & CUDA Versions:\")\n",
    "print(f\"üîπ PyTorch Version: {torch.__version__}\")\n",
    "print(f\"üîπ Torchvision Version: {torchvision.__version__}\")\n",
    "print(f\"üîπ NumPy Version: {np.__version__}\")\n",
    "print(f\"üîπ Pillow Version: {PIL.__version__}\")\n",
    "\n",
    "# Check CUDA\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"üîπ CUDA Available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    print(f\"üîπ CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"üîπ CUDA Current Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"üîπ CUDA Device Name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ 2. Verify Checkpoint File\n",
    "# ------------------------------\n",
    "print(\"\\nüìÇ Checking Checkpoint File:\")\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"‚úÖ Checkpoint found at: {os.path.abspath(CHECKPOINT_PATH)}\")\n",
    "    print(f\"‚úÖ Checkpoint Size: {os.path.getsize(CHECKPOINT_PATH) / (1024 * 1024):.2f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Checkpoint file NOT found.\")\n",
    "    exit()\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ 3. Load Checkpoint and Verify Keys\n",
    "# ------------------------------\n",
    "print(\"\\nüìú Checking Checkpoint Keys:\")\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "    print(f\"‚úÖ Found keys: {list(checkpoint.keys())}\")\n",
    "    \n",
    "    if \"generator_state\" in checkpoint:\n",
    "        print(\"‚úÖ 'generator_state' is present!\")\n",
    "    else:\n",
    "        print(\"‚ùå ERROR: 'generator_state' key is MISSING!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: Could not load checkpoint! {e}\")\n",
    "    exit()\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ 4. Compare Model State Dict\n",
    "# ------------------------------\n",
    "\n",
    "print(\"\\nüîç Checking Model Architecture Compatibility:\")\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "generator = UNetGenerator(input_nc=3, output_nc=1).to(device)\n",
    "\n",
    "# Load generator state\n",
    "try:\n",
    "    generator.load_state_dict(checkpoint[\"generator_state\"], strict=False)\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR: Model state_dict mismatch: {e}\")\n",
    "\n",
    "# Print model state keys\n",
    "print(\"\\nüõ†Ô∏è Model State Dict Keys:\")\n",
    "for name, param in generator.state_dict().items():\n",
    "    print(f\"üîπ {name}: {param.shape}\")\n",
    "\n",
    "# Print checkpoint state keys\n",
    "print(\"\\nüì¶ Checkpoint State Dict Keys:\")\n",
    "for key in checkpoint[\"generator_state\"]:\n",
    "    print(f\"üîπ {key}: {checkpoint['generator_state'][key].shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ **Diagnostics Complete!** Compare results with the working machine.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
